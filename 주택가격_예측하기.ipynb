{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "주택가격 예측하기.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s6VX7T5AwsK"
      },
      "source": [
        "!pip install --upgrade pip\r\n",
        "!pip install d2l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmUwYZmkA2Pi"
      },
      "source": [
        "!pip install mxnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYje_GB-FCMU"
      },
      "source": [
        "!git clone https://github.com/ghkdwjdrk123/pytorch.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD-7O2uTFUfZ"
      },
      "source": [
        "!cd pytorch\r\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0u71Mlf_qhp"
      },
      "source": [
        "import sys\r\n",
        "sys.path.insert(0, '..')\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "from d2l import torch as d2l\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from mxnet import autograd, gluon, init, nd\r\n",
        "from mxnet.gluon import data as gdata, loss as gloss, nn\r\n",
        "import numpy as np\r\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMfs8w58Bg7X"
      },
      "source": [
        "train_data = pd.read_csv('../data/train.csv')\r\n",
        "test_data = pd.read_csv('../data/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-j7Ds_jBs-7"
      },
      "source": [
        "print(train_data.shape)\r\n",
        "print(test_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utBOUJIwBvnq"
      },
      "source": [
        "train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhbhKQzxB2Ae"
      },
      "source": [
        "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii2h9SU1B4vo"
      },
      "source": [
        "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\r\n",
        "all_features[numeric_features] = all_features[numeric_features].apply(\r\n",
        "    lambda x: (x - x.mean()) / (x.std()))\r\n",
        "# After standardizing the data all means vanish, hence we can set missing\r\n",
        "# values to 0\r\n",
        "all_features = all_features.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeXUgXiMB6uJ"
      },
      "source": [
        "# Dummy_na=True refers to a missing value being a legal eigenvalue, and\r\n",
        "# creates an indicative feature for it\r\n",
        "all_features = pd.get_dummies(all_features, dummy_na=True)\r\n",
        "all_features.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHb1TRvOB8VU"
      },
      "source": [
        "n_train = train_data.shape[0]\r\n",
        "train_features = nd.array(all_features[:n_train].values)\r\n",
        "test_features = nd.array(all_features[n_train:].values)\r\n",
        "train_labels = nd.array(train_data.SalePrice.values).reshape((-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO_xDBLzB_l6"
      },
      "source": [
        "loss = gloss.L2Loss()\r\n",
        "\r\n",
        "def get_net():\r\n",
        "    net = nn.Sequential()\r\n",
        "    net.add(nn.Dense(1))\r\n",
        "    net.initialize()\r\n",
        "    return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu8dqmtGCBoa"
      },
      "source": [
        "def log_rmse(net, features, labels):\r\n",
        "    # To further stabilize the value when the logarithm is taken, set the\r\n",
        "    # value less than 1 as 1\r\n",
        "    clipped_preds = nd.clip(net(features), 1, float('inf'))\r\n",
        "    rmse = nd.sqrt(2 * loss(clipped_preds.log(), labels.log()).mean())\r\n",
        "    return rmse.asscalar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nakrH3CCDkL"
      },
      "source": [
        "def train(net, train_features, train_labels, test_features, test_labels,\r\n",
        "          num_epochs, learning_rate, weight_decay, batch_size):\r\n",
        "    train_ls, test_ls = [], []\r\n",
        "    train_iter = gdata.DataLoader(gdata.ArrayDataset(\r\n",
        "        train_features, train_labels), batch_size, shuffle=True)\r\n",
        "    # The Adam optimization algorithm is used here\r\n",
        "    trainer = gluon.Trainer(net.collect_params(), 'adam', {\r\n",
        "        'learning_rate': learning_rate, 'wd': weight_decay})\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        for X, y in train_iter:\r\n",
        "            with autograd.record():\r\n",
        "                l = loss(net(X), y)\r\n",
        "            l.backward()\r\n",
        "            trainer.step(batch_size)\r\n",
        "        train_ls.append(log_rmse(net, train_features, train_labels))\r\n",
        "        if test_labels is not None:\r\n",
        "            test_ls.append(log_rmse(net, test_features, test_labels))\r\n",
        "    return train_ls, test_ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XlOl0NGCGIK"
      },
      "source": [
        "\r\n",
        "def get_k_fold_data(k, i, X, y):\r\n",
        "    assert k > 1\r\n",
        "    fold_size = X.shape[0] // k\r\n",
        "    X_train, y_train = None, None\r\n",
        "    for j in range(k):\r\n",
        "        idx = slice(j * fold_size, (j + 1) * fold_size)\r\n",
        "        X_part, y_part = X[idx, :], y[idx]\r\n",
        "        if j == i:\r\n",
        "            X_valid, y_valid = X_part, y_part\r\n",
        "        elif X_train is None:\r\n",
        "            X_train, y_train = X_part, y_part\r\n",
        "        else:\r\n",
        "            X_train = nd.concat(X_train, X_part, dim=0)\r\n",
        "            y_train = nd.concat(y_train, y_part, dim=0)\r\n",
        "    return X_train, y_train, X_valid, y_valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjK3UrP3B1om"
      },
      "source": [
        "\r\n",
        "# This function has been saved in the d2l package for future use\r\n",
        "def semilogy(x_vals, y_vals, x_label, y_label, x2_vals=None, y2_vals=None,\r\n",
        "             legend=None, figsize=(3.5, 2.5)):\r\n",
        "    d2l.set_figsize(figsize)\r\n",
        "    d2l.plt.xlabel(x_label)\r\n",
        "    d2l.plt.ylabel(y_label)\r\n",
        "    d2l.plt.semilogy(x_vals, y_vals)\r\n",
        "    if x2_vals and y2_vals:\r\n",
        "        d2l.plt.semilogy(x2_vals, y2_vals, linestyle=':')\r\n",
        "        d2l.plt.legend(legend)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5a0EXTlCIRt"
      },
      "source": [
        "# https://ko.d2l.ai/chapter_deep-learning-basics/underfit-overfit.html?highlight=semilog#K-%EA%B2%B9-%EA%B5%90%EC%B0%A8-%EA%B2%80%EC%A6%9D(K%E2%80%8B-Fold-Cross-Validation)\r\n",
        "# 위의 링크에서 semilogy를 정의한 후에 '추후 사용을 위해 d2l 패키지에 넣어둘 것'이라고 써있네 ㅎ...\r\n",
        "def k_fold(k, X_train, y_train, num_epochs,\r\n",
        "           learning_rate, weight_decay, batch_size):\r\n",
        "    train_l_sum, valid_l_sum = 0, 0\r\n",
        "    for i in range(k):\r\n",
        "        data = get_k_fold_data(k, i, X_train, y_train)\r\n",
        "        net = get_net()\r\n",
        "        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,\r\n",
        "                                   weight_decay, batch_size)\r\n",
        "        train_l_sum += train_ls[-1]\r\n",
        "        valid_l_sum += valid_ls[-1]\r\n",
        "        if i == 0:\r\n",
        "            semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'rmse',\r\n",
        "                         range(1, num_epochs + 1), valid_ls,\r\n",
        "                         ['train', 'valid'])\r\n",
        "        print('fold %d, train rmse: %f, valid rmse: %f' % (\r\n",
        "            i, train_ls[-1], valid_ls[-1]))\r\n",
        "    return train_l_sum / k, valid_l_sum / k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2FXDTQpCJVv"
      },
      "source": [
        "k, num_epochs, lr, weight_decay, batch_size = 5, 100, 5, 0, 64\r\n",
        "train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr,\r\n",
        "                          weight_decay, batch_size)\r\n",
        "print('%d-fold validation: avg train rmse: %f, avg valid rmse: %f'\r\n",
        "      % (k, train_l, valid_l))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzx-aERuCQfY"
      },
      "source": [
        "\r\n",
        "def train_and_pred(train_features, test_feature, train_labels, test_data,\r\n",
        "                   num_epochs, lr, weight_decay, batch_size):\r\n",
        "    net = get_net()\r\n",
        "    train_ls, _ = train(net, train_features, train_labels, None, None,\r\n",
        "                        num_epochs, lr, weight_decay, batch_size)\r\n",
        "    semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'rmse')\r\n",
        "    print('train rmse %f' % train_ls[-1])\r\n",
        "    # Apply the network to the test set\r\n",
        "    preds = net(test_features).asnumpy()\r\n",
        "    # Reformat it for export to Kaggle\r\n",
        "    test_data['SalePrice'] = pd.Series(preds.reshape(1, -1)[0])\r\n",
        "    submission = pd.concat([test_data['Id'], test_data['SalePrice']], axis=1)\r\n",
        "    submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFNH1G5sCSTL"
      },
      "source": [
        "train_and_pred(train_features, test_features, train_labels, test_data,\r\n",
        "               num_epochs, lr, weight_decay, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}